use jsonrpsee::core::async_trait;
use jsonrpsee::core::RpcResult;
use jsonrpsee::proc_macros::rpc;
use jsonrpsee::types::error::ErrorObjectOwned as JsonRpseeError;
use jsonrpsee::types::error::INTERNAL_ERROR_CODE;
use jsonrpsee::types::error::INTERNAL_ERROR_MSG;
use jsonrpsee::types::ErrorObjectOwned;

use shc_common::types::ChunkId;
use shc_common::types::FileMetadata;
use shc_common::types::HasherOutT;
use shc_common::types::FILE_CHUNK_SIZE;
use shp_constants::BCSV_KEY_TYPE;
use sp_core::H256;
use sp_keystore::{Keystore, KeystorePtr};
use sp_runtime::AccountId32;
use sp_runtime::Deserialize;
use sp_runtime::Serialize;
use sp_trie::TrieLayout;

use shc_file_manager::traits::FileDataTrie;
use shc_file_manager::traits::FileStorage;
use shc_file_manager::traits::FileStorageError;
use shc_forest_manager::traits::ForestStorage;

use log::debug;
use log::error;

use std::fmt::Debug;
use std::fs::File;
use std::io::Read;
use std::io::Write;
use std::marker::PhantomData;
use std::path::PathBuf;
use std::sync::Arc;
use tokio::fs::create_dir_all;
use tokio::sync::RwLock;

const LOG_TARGET: &str = "storage-hub-client-rpc";

pub struct StorageHubClientRpcConfig<T, FL, FS> {
    pub file_storage: Arc<RwLock<FL>>,
    pub forest_storage: Arc<RwLock<FS>>,
    pub keystore: KeystorePtr,
    _marker: PhantomData<T>,
}

impl<T, FL, FS> Clone for StorageHubClientRpcConfig<T, FL, FS> {
    fn clone(&self) -> Self {
        Self {
            file_storage: self.file_storage.clone(),
            forest_storage: self.forest_storage.clone(),
            keystore: self.keystore.clone(),
            _marker: Default::default(),
        }
    }
}

impl<T, FL, FS> StorageHubClientRpcConfig<T, FL, FS>
where
    T: TrieLayout + Send + Sync + 'static,
    FL: FileStorage<T> + Send + Sync,
    FS: ForestStorage<T> + Send + Sync,
{
    pub fn new(
        file_storage: Arc<RwLock<FL>>,
        forest_storage: Arc<RwLock<FS>>,
        keystore: KeystorePtr,
    ) -> Self {
        Self {
            file_storage,
            forest_storage,
            keystore,
            _marker: Default::default(),
        }
    }
}

#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct IncompleteFileStatus {
    pub file_metadata: FileMetadata,
    pub stored_chunks: u64,
    pub total_chunks: u64,
}

#[derive(Clone, Debug, Serialize, Deserialize)]
pub enum SaveFileToDisk {
    FileNotFound,
    Success(FileMetadata),
    IncompleteFile(IncompleteFileStatus),
}

/// Provides an interface with the desired RPC method.
/// Used by the `rpc` macro from `jsonrpsee`
/// to generate the trait that is actually going to be implemented.
#[rpc(server, namespace = "storagehubclient")]
#[async_trait]
pub trait StorageHubClientApi {
    #[method(name = "loadFileInStorage")]
    async fn load_file_in_storage(
        &self,
        file_path: String,
        location: String,
        owner: AccountId32,
        bucket_id: H256,
    ) -> RpcResult<FileMetadata>;

    #[method(name = "saveFileToDisk")]
    async fn save_file_to_disk(
        &self,
        file_key: H256,
        file_path: String,
    ) -> RpcResult<SaveFileToDisk>;

    #[method(name = "getForestRoot")]
    async fn get_forest_root(&self) -> RpcResult<H256>;

    #[method(name = "rotateBcsvKeys")]
    async fn rotate_bcsv_keys(&self, seed: String) -> RpcResult<String>;
}

/// Stores the required objects to be used in our RPC method.
pub struct StorageHubClientRpc<T, FL, FS> {
    file_storage: Arc<RwLock<FL>>,
    forest_storage: Arc<RwLock<FS>>,
    keystore: KeystorePtr,
    _marker: PhantomData<T>,
}

impl<T, FL, FS> StorageHubClientRpc<T, FL, FS>
where
    T: TrieLayout + Send + Sync + 'static,
    FL: FileStorage<T> + Send + Sync,
    FS: ForestStorage<T> + Send + Sync,
{
    pub fn new(storage_hub_client_rpc_config: StorageHubClientRpcConfig<T, FL, FS>) -> Self {
        Self {
            file_storage: storage_hub_client_rpc_config.file_storage,
            forest_storage: storage_hub_client_rpc_config.forest_storage,
            keystore: storage_hub_client_rpc_config.keystore,
            _marker: Default::default(),
        }
    }
}

/// Interface generated by the `rpc` macro from our `StorageHubClientApi` trait.
// TODO: Currently the UserSendsFile task will react to all runtime events triggered by
// file uploads, even if the file is not in its storage. So we need a way to inform the task
// to only react to its file.
#[async_trait]
impl<T, FL, FS> StorageHubClientApiServer for StorageHubClientRpc<T, FL, FS>
where
    T: Send + Sync + TrieLayout + 'static,
    HasherOutT<T>: TryFrom<[u8; 32]>,
    FL: Send + Sync + FileStorage<T>,
    FS: Send + Sync + ForestStorage<T>,
{
    async fn load_file_in_storage(
        &self,
        file_path: String,
        location: String,
        owner: AccountId32,
        bucket_id: H256,
    ) -> RpcResult<FileMetadata> {
        // Open file in the local file system.
        let mut file = File::open(PathBuf::from(file_path.clone())).map_err(into_rpc_error)?;

        // Instantiate an "empty" [`FileDataTrie`] so we can write the file chunks into it.
        let mut file_data_trie = self.file_storage.write().await.new_file_data_trie();
        // A chunk id is simply an integer index.
        let mut chunk_id: u64 = 0;

        // Read file in chunks of [`FILE_CHUNK_SIZE`] into buffer then push buffer into a vector.
        // Loops until EOF or until some error that is NOT `ErrorKind::Interrupted` is found.
        // If `ErrorKind::Interrupted` is found, the operation is simply retried, as per
        // https://doc.rust-lang.org/std/io/trait.Read.html#errors-1
        loop {
            let mut chunk = Vec::with_capacity(FILE_CHUNK_SIZE as usize);
            let read_result = <File as Read>::by_ref(&mut file)
                .take(FILE_CHUNK_SIZE)
                .read_to_end(&mut chunk);
            match read_result {
                // Reached EOF, break loop.
                Ok(0) => {
                    debug!(target: LOG_TARGET, "Finished reading file");
                    break;
                }
                // Haven't reached EOF yet, continue loop.
                Ok(bytes_read) => {
                    debug!(target: LOG_TARGET, "Read {} bytes from file", bytes_read);

                    // Build the actual [`FileDataTrie`] by inserting each chunk into it.
                    file_data_trie
                        .write_chunk(&ChunkId::new(chunk_id), &chunk)
                        .map_err(into_rpc_error)?;
                    chunk_id += 1;
                }
                Err(e) => {
                    error!(target: LOG_TARGET, "Error when trying to read file: {:?}", e);
                    return Err(into_rpc_error(e));
                }
            }
        }

        // Generate the necessary metadata so we can insert file into the File Storage.
        let root = file_data_trie.get_root();
        let fs_metadata = file.metadata().map_err(into_rpc_error)?;

        if fs_metadata.len() == 0 {
            return Err(into_rpc_error(FileStorageError::FileIsEmpty));
        }

        // Build StorageHub's [`FileMetadata`]
        let file_metadata = FileMetadata {
            owner: <AccountId32 as AsRef<[u8]>>::as_ref(&owner).to_vec(),
            bucket_id: bucket_id.as_ref().to_vec(),
            file_size: fs_metadata.len(),
            fingerprint: root.as_ref().into(),
            location: location.clone().into(),
        };
        let file_key = file_metadata.file_key::<T::Hash>();

        // Acquire FileStorage write lock.
        let mut file_storage_write_lock = self.file_storage.write().await;

        // Finally store file in File Storage.
        file_storage_write_lock
            .insert_file_with_data(file_key, file_metadata.clone(), file_data_trie)
            .map_err(into_rpc_error)?;

        Ok(file_metadata)
    }

    async fn save_file_to_disk(
        &self,
        file_key: H256,
        file_path: String,
    ) -> RpcResult<SaveFileToDisk> {
        // Acquire FileStorage read lock.
        let read_file_storage = self.file_storage.read().await;

        let file_key_hash: HasherOutT<T> = TryFrom::<[u8; 32]>::try_from(file_key.to_fixed_bytes())
            .map_err(|_| into_rpc_error("Invalid file key hash"))?;

        // Retrieve file metadata from File Storage.
        let file_metadata = match read_file_storage.get_metadata(&file_key_hash) {
            Ok(metadata) => metadata,
            Err(FileStorageError::FileDoesNotExist) => return Ok(SaveFileToDisk::FileNotFound),
            Err(e) => return Err(into_rpc_error(e)),
        };

        // Check if file is incomplete.
        let stored_chunks = read_file_storage
            .stored_chunks_count(&file_key_hash)
            .map_err(into_rpc_error)?;
        let total_chunks = file_metadata.chunks_count();

        if stored_chunks < total_chunks {
            return Ok(SaveFileToDisk::IncompleteFile(IncompleteFileStatus {
                file_metadata,
                stored_chunks,
                total_chunks,
            }));
        }

        let file_path = PathBuf::from(file_path.clone());

        // Create parent directories if they don't exist.
        create_dir_all(&file_path.parent().unwrap())
            .await
            .map_err(into_rpc_error)?;

        // Open file in the local file system.
        let mut file = File::create(PathBuf::from(file_path.clone())).map_err(into_rpc_error)?;

        // Write file data to disk.
        for chunk_id in 0..total_chunks {
            let chunk_id = ChunkId::new(chunk_id);
            let chunk = read_file_storage
                .get_chunk(&file_key_hash, &chunk_id)
                .map_err(into_rpc_error)?;
            file.write_all(&chunk).map_err(into_rpc_error)?;
        }

        Ok(SaveFileToDisk::Success(file_metadata))
    }

    async fn get_forest_root(&self) -> RpcResult<H256> {
        let forest_storage_read_lock = self.forest_storage.read().await;
        let root = forest_storage_read_lock.root();
        let root = H256::from_slice(root.as_ref());
        Ok(root)
    }

    async fn rotate_bcsv_keys(&self, seed: String) -> RpcResult<String> {
        let new_pub_key = self
            .keystore
            .sr25519_generate_new(BCSV_KEY_TYPE, Some(seed.as_ref()))
            .map_err(into_rpc_error)?;

        Ok(new_pub_key.to_string())
    }
}

/// Converts into the expected kind of error for `jsonrpsee`'s `RpcResult<_>`.
fn into_rpc_error(e: impl Debug) -> JsonRpseeError {
    ErrorObjectOwned::owned(
        INTERNAL_ERROR_CODE,
        INTERNAL_ERROR_MSG,
        Some(format!("{:?}", e)),
    )
}
